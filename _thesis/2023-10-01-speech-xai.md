---
title: "Speech XAI, explaining reasons behind speech model predictions"
permalink: /thesis/2023-10-01-speech-xai/
collection: thesis
status: available
contact_name: "Alkis Koudounas"
contact: "alkis.koudounas@polito.it"
---

<a href="https://en.wikipedia.org/wiki/Audio_signal_processing"><img src="https://img.shields.io/badge/Audio%20&%20Speech%20Processing-blue" alt="Audio Processing"></a>

![immagine](/images/speech_xai.png)

from *[The AI Summer](https://theaisummer.com/xai/)* 

Speech XAI focuses on providing insights into the reasons behind predictions made by speech models. This emerging field aims to enhance transparency and interpretability in speech recognition and synthesis systems. By employing various techniques such as attention mechanisms, saliency maps, and feature importance analysis, Speech XAI enables users to understand why a particular prediction was made. This empowers users to gain insights into the underlying decision-making processes of speech models, fostering trust, accountability, and enabling targeted improvements to ensure more accurate and reliable speech-based applications.

The **main objectives** of this thesis are:
- Analyze the state-of-the-art XAI techniques.
- Design a novel pipeline to analyze and debug speech models and their predictions.
- Demonstrate the effectiveness of the proposed approach using renowned benchmarks (e.g., [SUPERB](https://superbbenchmark.org/)).

**References:**

1. [Towards Relatable Explainable AI with the Perceptual Process](https://dl.acm.org/doi/fullHtml/10.1145/3491102.3501826)
2. [Exploring Subgroup Performance in End-to-End Speech Models](https://ieeexplore.ieee.org/abstract/document/10095284/)
3. [Towards Measuring Fairness in Speech Recognition](https://arxiv.org/abs/2111.09983)
4. [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)